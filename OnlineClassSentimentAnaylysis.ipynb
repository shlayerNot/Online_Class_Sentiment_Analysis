{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Import fundamentals\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "# Import nltk and download punkt, wordnet\n",
    "import nltk\n",
    "\n",
    "# Import word_tokenize and stopwords from nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer \n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# I will keep the resulting plots\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable Jupyter Notebook's intellisense\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "# We want to see whole content (non-truncated)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@lynn93630469 Support my little sister in her school by buying a laptop for her Online Class and a stable wifi connection in our home. She badly needs it because she only uses an android phone and a data connection. ğŸ˜Š Whenever she has something to encode she borrows laptop from our cousin's.</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yan, tama yan. Dapat lang na nasa #1 &amp;amp; #2 ang tags natin, aba! Pambawi sa puyat ko, hahaha. Alas-kwatro na ako nakatulog kanina dahil sa SBEN19 MAPA tapos gumising ng 7 AM para sa online class ğŸ˜¬  STREAM SBEN19MAPA @SB19Official #SBEN19MAPAOutNow #SBNineteenAtKalayaan2021</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kabi-kbila na ang utang ko dahil sa online class n toğŸ¥ºğŸ¥º panload pa lng di ko n affordğŸ¥º   Need some helpğŸ™ğŸ™ğŸ¥º</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GoodmorningğŸŒ Online class is realğŸ˜‚</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>umay sa globe fiber. goodluck pag may online class na talaga.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                 Tweets  \\\n",
       "0  @lynn93630469 Support my little sister in her school by buying a laptop for her Online Class and a stable wifi connection in our home. She badly needs it because she only uses an android phone and a data connection. ğŸ˜Š Whenever she has something to encode she borrows laptop from our cousin's.   \n",
       "1  Yan, tama yan. Dapat lang na nasa #1 &amp; #2 ang tags natin, aba! Pambawi sa puyat ko, hahaha. Alas-kwatro na ako nakatulog kanina dahil sa SBEN19 MAPA tapos gumising ng 7 AM para sa online class ğŸ˜¬  STREAM SBEN19MAPA @SB19Official #SBEN19MAPAOutNow #SBNineteenAtKalayaan2021                    \n",
       "2  Kabi-kbila na ang utang ko dahil sa online class n toğŸ¥ºğŸ¥º panload pa lng di ko n affordğŸ¥º   Need some helpğŸ™ğŸ™ğŸ¥º                                                                                                                                                                                             \n",
       "3  GoodmorningğŸŒ Online class is realğŸ˜‚                                                                                                                                                                                                                                                                     \n",
       "4  umay sa globe fiber. goodluck pag may online class na talaga.                                                                                                                                                                                                                                          \n",
       "\n",
       "      Label  \n",
       "0  Neutral   \n",
       "1  Neutral   \n",
       "2  Negative  \n",
       "3  Neutral   \n",
       "4  Negative  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the tweets\n",
    "tweets = pd.read_csv(\"Dataset.csv\")\n",
    "\n",
    "# Print the first five rows\n",
    "display(tweets.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the text file containing the Filipino Stopwords based from https://github.com/stopwords-iso/stopwords-tl\n",
    "\n",
    "file = open(\"StopWords/flstopwords.txt\", \"r\", encoding=\"utf8\")\n",
    "flstopwords = file.read().split(\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>support little sister school buying laptop online class stable wifi connection home badly needs uses android phone data connection whenever something encode borrows laptop cousin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yan tama yan lang nasa amp tags natin aba pambawi puyat hahaha nakatulog kanina sben mapa tapos gumising online class stream sbenmapa sbenmapaoutnow sbnineteenatkalayaan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>utang online class panload lng need</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>online class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>umay globe fiber goodluck pag online class talaga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mad last october first semester terpaksa jahindi online class ended class semester last thursday sin hindid deserve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>online class ayoko mag enroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sinusulit lang yung year online class law school palaging bahay lang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>today using lot khursus online class watching stream movie lastly playing game wow day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>know hinhindi tlaga pwede online class nakatulog lecture hahahahahahaha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>wrong timing laptop nasira kelan need online class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>buong araw nasa upuan online class charot donbelle pakigalawangupuan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>slept good night next morning woke feeling refreshed good mood teaching online class still smiling calm although children hardly sit still zoom stress younger kids needed physical class play learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>online class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>back days soc med detox putangina pagod pagod mayakap kaibigan mawala pagod hinhindi kinakaya sobrang bigat online class please ayoko ganito sobrang hirap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                               Processed\n",
       "0   support little sister school buying laptop online class stable wifi connection home badly needs uses android phone data connection whenever something encode borrows laptop cousin                  \n",
       "1   yan tama yan lang nasa amp tags natin aba pambawi puyat hahaha nakatulog kanina sben mapa tapos gumising online class stream sbenmapa sbenmapaoutnow sbnineteenatkalayaan                           \n",
       "2   utang online class panload lng need                                                                                                                                                                 \n",
       "3   online class                                                                                                                                                                                        \n",
       "4   umay globe fiber goodluck pag online class talaga                                                                                                                                                   \n",
       "5   mad last october first semester terpaksa jahindi online class ended class semester last thursday sin hindid deserve                                                                                 \n",
       "6   online class ayoko mag enroll                                                                                                                                                                       \n",
       "7   sinusulit lang yung year online class law school palaging bahay lang                                                                                                                                \n",
       "8   today using lot khursus online class watching stream movie lastly playing game wow day                                                                                                              \n",
       "9   know hinhindi tlaga pwede online class nakatulog lecture hahahahahahaha                                                                                                                             \n",
       "10  wrong timing laptop nasira kelan need online class                                                                                                                                                  \n",
       "11  buong araw nasa upuan online class charot donbelle pakigalawangupuan                                                                                                                                \n",
       "12  slept good night next morning woke feeling refreshed good mood teaching online class still smiling calm although children hardly sit still zoom stress younger kids needed physical class play learn\n",
       "13  online class                                                                                                                                                                                        \n",
       "14  back days soc med detox putangina pagod pagod mayakap kaibigan mawala pagod hinhindi kinakaya sobrang bigat online class please ayoko ganito sobrang hirap                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on Wed Aug  5 15:39:20 2020\n",
    "\n",
    "@author: bhasfe\n",
    "\"\"\"\n",
    "def process_tweets(tweet):\n",
    "            \n",
    "    tweet = re.sub(r\"won't\", \"will not\", tweet)\n",
    "    tweet = re.sub(r\"can't\", \"can not\", tweet)\n",
    "    tweet = re.sub(r\"n't\", \" not\", tweet)\n",
    "    tweet = re.sub(r\"'ve\", \" have\", tweet)\n",
    "    tweet = re.sub(r\"'ll\", \" will\", tweet)\n",
    "    tweet = re.sub(r\"'re\", \" are\", tweet)\n",
    "    \n",
    "    tweet = re.sub(r\"'di\", \"hindi\", tweet)\n",
    "    tweet = re.sub(r\"di\", \"hindi\", tweet)\n",
    "    \n",
    "    # Remove links\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet, flags=re.MULTILINE)\n",
    "    \n",
    "    #remove numbers\n",
    "    tweet = re.sub(r'\\d','', tweet)\n",
    "    \n",
    "    # Remove mentions and hashtag\n",
    "    tweet = re.sub(r'\\@\\w+|\\#','', tweet)\n",
    "   \n",
    "    # clean the words\n",
    "    clean = word_tokenize(tweet)\n",
    "\n",
    "    # Remove the English stop words\n",
    "    clean = [token for token in clean if token not in stopwords.words(\"english\")]\n",
    "    \n",
    "    #Remove the Filipino stop words\n",
    "    clean = [token for token in clean if token not in flstopwords]\n",
    "    \n",
    "    # Remove non-alphabetic characters and keep the words contains three or more letters\n",
    "    clean = [token for token in clean if token.isalpha() and len(token)>2]\n",
    "    \n",
    "    clean = ' '.join(clean)\n",
    "    return clean\n",
    "    \n",
    "# Call the function and store the result into a new column\n",
    "tweets[\"Processed\"] = tweets[\"Tweets\"].str.lower().apply(process_tweets)\n",
    "\n",
    "display(tweets[[\"Processed\"]].head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>support littl sister school buy laptop onlin class stabl wifi connect home badli need us android phone data connect whenev someth encod borrow laptop cousin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yan tama yan lang nasa amp tag natin aba pambawi puyat hahaha nakatulog kanina sben mapa tapo gumis onlin class stream sbenmapa sbenmapaoutnow sbnineteenatkalayaan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>utang onlin class panload lng need</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>onlin class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>umay globe fiber goodluck pag onlin class talaga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mad last octob first semest terpaksa jahindi onlin class end class semest last thursday sin hindid deserv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>onlin class ayoko mag enrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sinusulit lang yung year onlin class law school palag bahay lang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>today use lot khursu onlin class watch stream movi lastli play game wow day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>know hinhindi tlaga pwede onlin class nakatulog lectur hahahahahahaha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>wrong time laptop nasira kelan need onlin class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>buong araw nasa upuan onlin class charot donbel pakigalawangupuan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>slept good night next morn woke feel refresh good mood teach onlin class still smile calm although child hardli sit still zoom stress young kid need physic class play learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>onlin class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>back day soc med detox putangina pagod pagod mayakap kaibigan mawala pagod hinhindi kinakaya sobrang bigat onlin class plea ayoko ganito sobrang hirap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                       Processed\n",
       "0   support littl sister school buy laptop onlin class stabl wifi connect home badli need us android phone data connect whenev someth encod borrow laptop cousin                \n",
       "1   yan tama yan lang nasa amp tag natin aba pambawi puyat hahaha nakatulog kanina sben mapa tapo gumis onlin class stream sbenmapa sbenmapaoutnow sbnineteenatkalayaan         \n",
       "2   utang onlin class panload lng need                                                                                                                                          \n",
       "3   onlin class                                                                                                                                                                 \n",
       "4   umay globe fiber goodluck pag onlin class talaga                                                                                                                            \n",
       "5   mad last octob first semest terpaksa jahindi onlin class end class semest last thursday sin hindid deserv                                                                   \n",
       "6   onlin class ayoko mag enrol                                                                                                                                                 \n",
       "7   sinusulit lang yung year onlin class law school palag bahay lang                                                                                                            \n",
       "8   today use lot khursu onlin class watch stream movi lastli play game wow day                                                                                                 \n",
       "9   know hinhindi tlaga pwede onlin class nakatulog lectur hahahahahahaha                                                                                                       \n",
       "10  wrong time laptop nasira kelan need onlin class                                                                                                                             \n",
       "11  buong araw nasa upuan onlin class charot donbel pakigalawangupuan                                                                                                           \n",
       "12  slept good night next morn woke feel refresh good mood teach onlin class still smile calm although child hardli sit still zoom stress young kid need physic class play learn\n",
       "13  onlin class                                                                                                                                                                 \n",
       "14  back day soc med detox putangina pagod pagod mayakap kaibigan mawala pagod hinhindi kinakaya sobrang bigat onlin class plea ayoko ganito sobrang hirap                      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def NormalizeWithPOS(text):\n",
    "    # Lemmatization & Stemming according to POS tagging\n",
    "\n",
    "    word_list = word_tokenize(text)\n",
    "    rev = []\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    stemmer = PorterStemmer() \n",
    "    for word, tag in pos_tag(word_list):\n",
    "        if tag.startswith('J'):\n",
    "            w = lemmatizer.lemmatize(word, pos='a')\n",
    "        elif tag.startswith('V'):\n",
    "            w = lemmatizer.lemmatize(word, pos='v')\n",
    "        elif tag.startswith('N'):\n",
    "            w = lemmatizer.lemmatize(word, pos='n')\n",
    "        elif tag.startswith('R'):\n",
    "            w = lemmatizer.lemmatize(word, pos='r')\n",
    "        else:\n",
    "            w = word\n",
    "        #w = stemmer.stem(w)\n",
    "        rev.append(w)\n",
    "    tweet = ' '.join(rev)\n",
    "    return tweet\n",
    "\n",
    "tweets[\"Processed\"] = tweets[\"Processed\"].apply(NormalizeWithPOS)\n",
    "display(tweets[[\"Processed\"]].head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaaaaaa</th>\n",
       "      <th>aabot</th>\n",
       "      <th>aabsent</th>\n",
       "      <th>aadjust</th>\n",
       "      <th>aalaga</th>\n",
       "      <th>aantay</th>\n",
       "      <th>aaral</th>\n",
       "      <th>aaralin</th>\n",
       "      <th>aasawa</th>\n",
       "      <th>aattend</th>\n",
       "      <th>...</th>\n",
       "      <th>ÂªÃ°Ã¿</th>\n",
       "      <th>Ã¢Å“Å¡</th>\n",
       "      <th>Å“Ã°Ã¿</th>\n",
       "      <th>ğ‚ğ¡ğšğ¢ğ§</th>\n",
       "      <th>ğŒğšğ§ğšğ ğğ¦ğğ§ğ­</th>\n",
       "      <th>ğğ§ğ¥ğ¢ğ§ğ</th>\n",
       "      <th>ğğ€ğ’ğˆğ€</th>\n",
       "      <th>ğğ®ğ›ğ¥ğ¢ğœ</th>\n",
       "      <th>ğ’ğ®ğ©ğ©ğ¥ğ²</th>\n",
       "      <th>ğ“ğ«ğšğ¢ğ§ğ¢ğ§ğ </th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4897 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaaaaaa  aabot  aabsent  aadjust  aalaga  aantay  aaral  aaralin  aasawa  \\\n",
       "0  0.0      0.0    0.0      0.0      0.0     0.0     0.0    0.0      0.0      \n",
       "1  0.0      0.0    0.0      0.0      0.0     0.0     0.0    0.0      0.0      \n",
       "2  0.0      0.0    0.0      0.0      0.0     0.0     0.0    0.0      0.0      \n",
       "3  0.0      0.0    0.0      0.0      0.0     0.0     0.0    0.0      0.0      \n",
       "4  0.0      0.0    0.0      0.0      0.0     0.0     0.0    0.0      0.0      \n",
       "\n",
       "   aattend  ...  ÂªÃ°Ã¿  Ã¢Å“Å¡  Å“Ã°Ã¿  ğ‚ğ¡ğšğ¢ğ§  ğŒğšğ§ğšğ ğğ¦ğğ§ğ­  ğğ§ğ¥ğ¢ğ§ğ  ğğ€ğ’ğˆğ€  ğğ®ğ›ğ¥ğ¢ğœ  \\\n",
       "0  0.0      ...  0.0  0.0  0.0  0.0    0.0         0.0     0.0    0.0      \n",
       "1  0.0      ...  0.0  0.0  0.0  0.0    0.0         0.0     0.0    0.0      \n",
       "2  0.0      ...  0.0  0.0  0.0  0.0    0.0         0.0     0.0    0.0      \n",
       "3  0.0      ...  0.0  0.0  0.0  0.0    0.0         0.0     0.0    0.0      \n",
       "4  0.0      ...  0.0  0.0  0.0  0.0    0.0         0.0     0.0    0.0      \n",
       "\n",
       "   ğ’ğ®ğ©ğ©ğ¥ğ²  ğ“ğ«ğšğ¢ğ§ğ¢ğ§ğ   \n",
       "0  0.0     0.0       \n",
       "1  0.0     0.0       \n",
       "2  0.0     0.0       \n",
       "3  0.0     0.0       \n",
       "4  0.0     0.0       \n",
       "\n",
       "[5 rows x 4897 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfidf_stops = [\"online\", \"class\", \"course\", \"learning\", \"learn\",\"teach\", \"teaching\", \"distance\", \\\n",
    "               \"distancelearning\", \"education\", \"teacher\", \"student\", \"grade\", \"classes\", \"computer\", \"resource\", \\\n",
    "               \"onlineeducation\", \"onlinelearning\", \"school\", \"students\", \"class\", \"virtual\", \"eschool\", \"thing\", \\\n",
    "               \"virtuallearning\", \"educated\", \"educates\", \"teaches\", \"studies\", \"study\", \"semester\", \"elearning\", \\\n",
    "               \"teachers\", \"lecturer\", \"lecture\", \"amp\", \"academic\", \"admission\", \"academician\", \"account\", \"action\",\\\n",
    "               \"add\", \"app\", \"announcement\", \"application\", \"adult\", \"classroom\", \"system\", \"video\", \"essay\", \"training\", \\\n",
    "               \"homework\",\"work\",\"assignment\", \"paper\", \"get\", \"math\", \"project\", \"science\", \"physics\", \"lesson\", \"schools\", \\\n",
    "               \"courses\", \"assignments\", \"know\", \"instruction\",\"email\", \"discussion\",\"home\", \"college\", \"exam\", \"university\", \\\n",
    "               \"use\", \"fall\", \"term\", \"proposal\", \"one\", \"review\", \"proposal\", \"calculus\", \"search\", \"research\", \"algebra\", \\\n",
    "               \"internet\", \"remote\", \"remotelearning\"]\n",
    "\n",
    "enstopwords = set(stopwords.words('english'))\n",
    "        \n",
    "# Initialize a Tf-idf Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, stop_words=enstopwords and flstopwords and tfidf_stops)\n",
    "\n",
    "# Fit and transform the vectorizer corpus = [str (item) for item in corpus]\n",
    "tfidf_matrix = vectorizer.fit_transform(str (item) for item in tweets[\"Processed\"])\n",
    "\n",
    "# Let's see what we have\n",
    "tfidf_matrix\n",
    "\n",
    "# Create a DataFrame for tf-idf vectors and display the first five rows\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns= vectorizer.get_feature_names())\n",
    "display(tfidf_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features and the target\n",
    "X = tfidf_matrix\n",
    "y = tweets[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size = .20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confussionMatrix(cl,X_test,y_test):\n",
    "    # Predict the labels\n",
    "    y_pred = cl.predict(X_test)\n",
    "    \n",
    "    # Print the Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix\\n\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Print the Classification Report\n",
    "    cr = classification_report(y_test, y_pred)\n",
    "    print(\"\\n\\nClassification Report\\n\")\n",
    "    print(cr)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[679 246   0]\n",
      " [236 672   0]\n",
      " [ 47 121   0]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.71      0.73      0.72       925\n",
      "     Neutral       0.65      0.74      0.69       908\n",
      "    Positive       0.00      0.00      0.00       168\n",
      "\n",
      "    accuracy                           0.68      2001\n",
      "   macro avg       0.45      0.49      0.47      2001\n",
      "weighted avg       0.62      0.68      0.65      2001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#1 Multinomial Naive Bayes\n",
    "mnb = MultinomialNB()\n",
    "#train our algorithm\n",
    "mnb.fit(X_train, y_train)\n",
    "#Test the trained classifier\n",
    "predicted_class = mnb.predict(X_test)\n",
    "#print('Accuracy of MNB for this dataset: %3.2f' %  (accuracy_score(y_test, predicted_class)*100))\n",
    "confussionMatrix(mnb,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[694 172  59]\n",
      " [275 515 118]\n",
      " [ 44  72  52]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.69      0.75      0.72       925\n",
      "     Neutral       0.68      0.57      0.62       908\n",
      "    Positive       0.23      0.31      0.26       168\n",
      "\n",
      "    accuracy                           0.63      2001\n",
      "   macro avg       0.53      0.54      0.53      2001\n",
      "weighted avg       0.64      0.63      0.63      2001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2 Complement Naive Bayes\n",
    "cnb = ComplementNB()\n",
    "\n",
    "cnb.fit(X_train, y_train)\n",
    "predicted_class = cnb.predict(X_test)\n",
    "#print('Accuracy of MNB for this dataset: %3.2f' %  (accuracy_score(y_test, predicted_class)*100))\n",
    "confussionMatrix(cnb,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[630 266  29]\n",
      " [194 664  50]\n",
      " [ 40 112  16]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.73      0.68      0.70       925\n",
      "     Neutral       0.64      0.73      0.68       908\n",
      "    Positive       0.17      0.10      0.12       168\n",
      "\n",
      "    accuracy                           0.65      2001\n",
      "   macro avg       0.51      0.50      0.50      2001\n",
      "weighted avg       0.64      0.65      0.64      2001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3 Bernoulli Naive Bayes classifier\n",
    "nb = BernoulliNB()\n",
    "\n",
    "# Fit the model\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "predicted_class = nb.predict(X_test)\n",
    "#print('Accuracy of Gaussian Naive Bayes for this dataset: %3.2f' %  (accuracy_score(y_test, predicted_class)*100))\n",
    "confussionMatrix(nb,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaaaaaa',\n",
       " 'aabot',\n",
       " 'aabsent',\n",
       " 'aadjust',\n",
       " 'aalaga',\n",
       " 'aantay',\n",
       " 'aaral',\n",
       " 'aaralin',\n",
       " 'aasawa',\n",
       " 'aattend',\n",
       " 'aaway',\n",
       " 'aayo',\n",
       " 'aayusin',\n",
       " 'aba',\n",
       " 'abala',\n",
       " 'abi',\n",
       " 'abl',\n",
       " 'abot',\n",
       " 'absent',\n",
       " 'absolut',\n",
       " 'abt',\n",
       " 'abusado',\n",
       " 'abutan',\n",
       " 'abutin',\n",
       " 'acad',\n",
       " 'academ',\n",
       " 'academi',\n",
       " 'academicbreaknow',\n",
       " 'academiceasenow',\n",
       " 'academicfreez',\n",
       " 'academicfreezenow',\n",
       " 'acc',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'accessori',\n",
       " 'acct',\n",
       " 'ace',\n",
       " 'ach',\n",
       " 'achiev',\n",
       " 'acr',\n",
       " 'act',\n",
       " 'activ',\n",
       " 'activit',\n",
       " 'actual',\n",
       " 'adapt',\n",
       " 'address',\n",
       " 'adel',\n",
       " 'adjust',\n",
       " 'administr',\n",
       " 'admit',\n",
       " 'adopt',\n",
       " 'ador',\n",
       " 'advanc',\n",
       " 'advantag',\n",
       " 'advic',\n",
       " 'advis',\n",
       " 'affect',\n",
       " 'afford',\n",
       " 'afraid',\n",
       " 'afternoon',\n",
       " 'aga',\n",
       " 'agad',\n",
       " 'agahan',\n",
       " 'age',\n",
       " 'agent',\n",
       " 'ago',\n",
       " 'agre',\n",
       " 'ahaha',\n",
       " 'ahahah',\n",
       " 'ahahaha',\n",
       " 'ahahahah',\n",
       " 'ahahahaha',\n",
       " 'ahahahahaha',\n",
       " 'ahead',\n",
       " 'ahh',\n",
       " 'ahhaha',\n",
       " 'ahhahahaha',\n",
       " 'ahhh',\n",
       " 'ahindi',\n",
       " 'ahindib',\n",
       " 'aigoo',\n",
       " 'aim',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'aircon',\n",
       " 'akala',\n",
       " 'akalain',\n",
       " 'akong',\n",
       " 'akoo',\n",
       " 'akooo',\n",
       " 'akoooo',\n",
       " 'akooooooo',\n",
       " 'akoy',\n",
       " 'aku',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alab',\n",
       " 'alaga',\n",
       " 'alak',\n",
       " 'alalahanin',\n",
       " 'alam',\n",
       " 'alang',\n",
       " 'alarm',\n",
       " 'alaw',\n",
       " 'album',\n",
       " 'alexa',\n",
       " 'ali',\n",
       " 'aligaga',\n",
       " 'aliw',\n",
       " 'allergi',\n",
       " 'allow',\n",
       " 'almost',\n",
       " 'almus',\n",
       " 'alon',\n",
       " 'along',\n",
       " 'alreadi',\n",
       " 'alright',\n",
       " 'alslif',\n",
       " 'also',\n",
       " 'alsteach',\n",
       " 'altern',\n",
       " 'although',\n",
       " 'alway',\n",
       " 'amanda',\n",
       " 'amazinglybeaut',\n",
       " 'ambag',\n",
       " 'ambobo',\n",
       " 'amen',\n",
       " 'amidst',\n",
       " 'aminado',\n",
       " 'aminin',\n",
       " 'amo',\n",
       " 'among',\n",
       " 'amount',\n",
       " 'ampanget',\n",
       " 'ampota',\n",
       " 'ampotek',\n",
       " 'amputa',\n",
       " 'amputek',\n",
       " 'ana',\n",
       " 'anak',\n",
       " 'analysi',\n",
       " 'analyz',\n",
       " 'anang',\n",
       " 'anatomi',\n",
       " 'andam',\n",
       " 'andami',\n",
       " 'andon',\n",
       " 'andoon',\n",
       " 'android',\n",
       " 'andun',\n",
       " 'andyan',\n",
       " 'ane',\n",
       " 'anga',\n",
       " 'angel',\n",
       " 'anhindi',\n",
       " 'anhindito',\n",
       " 'ani',\n",
       " 'anim',\n",
       " 'anjan',\n",
       " 'anlaka',\n",
       " 'anniversari',\n",
       " 'announc',\n",
       " 'annoy',\n",
       " 'anona',\n",
       " 'anong',\n",
       " 'anoth',\n",
       " 'ansab',\n",
       " 'ansaya',\n",
       " 'answer',\n",
       " 'antag',\n",
       " 'anti',\n",
       " 'antok',\n",
       " 'antukin',\n",
       " 'anu',\n",
       " 'anuena',\n",
       " 'anuenaaa',\n",
       " 'anuna',\n",
       " 'anung',\n",
       " 'anxieti',\n",
       " 'anxiou',\n",
       " 'anxious',\n",
       " 'anyar',\n",
       " 'anymor',\n",
       " 'anyon',\n",
       " 'anyth',\n",
       " 'anytim',\n",
       " 'anyway',\n",
       " 'apaka',\n",
       " 'apec',\n",
       " 'apektado',\n",
       " 'apo',\n",
       " 'apolog',\n",
       " 'appli',\n",
       " 'applic',\n",
       " 'appreci',\n",
       " 'approach',\n",
       " 'april',\n",
       " 'aral',\n",
       " 'aralan',\n",
       " 'aralin',\n",
       " 'arat',\n",
       " 'araw',\n",
       " 'architectur',\n",
       " 'area',\n",
       " 'argh',\n",
       " 'ari',\n",
       " 'armi',\n",
       " 'aron',\n",
       " 'around',\n",
       " 'arriv',\n",
       " 'art',\n",
       " 'articl',\n",
       " 'artwork',\n",
       " 'as',\n",
       " 'asa',\n",
       " 'asan',\n",
       " 'asap',\n",
       " 'asar',\n",
       " 'asid',\n",
       " 'asikasuhin',\n",
       " 'ask',\n",
       " 'askjerom',\n",
       " 'askricci',\n",
       " 'asnychron',\n",
       " 'aso',\n",
       " 'assalamualaikum',\n",
       " 'assam',\n",
       " 'assess',\n",
       " 'assign',\n",
       " 'assist',\n",
       " 'associ',\n",
       " 'astig',\n",
       " 'asu',\n",
       " 'asynchron',\n",
       " 'ata',\n",
       " 'atang',\n",
       " 'atay',\n",
       " 'atbp',\n",
       " 'ate',\n",
       " 'ateee',\n",
       " 'ateeee',\n",
       " 'athena',\n",
       " 'athenaxlui',\n",
       " 'atleast',\n",
       " 'atm',\n",
       " 'attack',\n",
       " 'attend',\n",
       " 'attenhind',\n",
       " 'attent',\n",
       " 'au',\n",
       " 'audac',\n",
       " 'aug',\n",
       " 'august',\n",
       " 'auhindio',\n",
       " 'auhindit',\n",
       " 'aunti',\n",
       " 'auto',\n",
       " 'autodata',\n",
       " 'automat',\n",
       " 'avail',\n",
       " 'averag',\n",
       " 'awa',\n",
       " 'awak',\n",
       " 'awang',\n",
       " 'awar',\n",
       " 'award',\n",
       " 'away',\n",
       " 'awit',\n",
       " 'awittt',\n",
       " 'awkward',\n",
       " 'awra',\n",
       " 'awt',\n",
       " 'aww',\n",
       " 'axi',\n",
       " 'ayako',\n",
       " 'ayan',\n",
       " 'ayaw',\n",
       " 'ayi',\n",
       " 'ayo',\n",
       " 'ayoko',\n",
       " 'ayokong',\n",
       " 'ayon',\n",
       " 'ayq',\n",
       " 'ayt',\n",
       " 'ayu',\n",
       " 'ayuko',\n",
       " 'ayun',\n",
       " 'ayusin',\n",
       " 'ayyyi',\n",
       " 'bab',\n",
       " 'baba',\n",
       " 'babad',\n",
       " 'babagsak',\n",
       " 'babait',\n",
       " 'babalik',\n",
       " 'babangon',\n",
       " 'babantay',\n",
       " 'babayad',\n",
       " 'babayaran',\n",
       " 'babe',\n",
       " 'babi',\n",
       " 'babii',\n",
       " 'baby',\n",
       " 'bachelor',\n",
       " 'back',\n",
       " 'background',\n",
       " 'backlog',\n",
       " 'backpain',\n",
       " 'backtoschool',\n",
       " 'bacoor',\n",
       " 'bad',\n",
       " 'badg',\n",
       " 'badli',\n",
       " 'badtrip',\n",
       " 'bag',\n",
       " 'bagal',\n",
       " 'bagay',\n",
       " 'baget',\n",
       " 'bagong',\n",
       " 'bagsak',\n",
       " 'baguio',\n",
       " 'bagyo',\n",
       " 'bahala',\n",
       " 'bahalakayojan',\n",
       " 'bahay',\n",
       " 'baka',\n",
       " 'bakasyon',\n",
       " 'baket',\n",
       " 'bakla',\n",
       " 'bakuna',\n",
       " 'bala',\n",
       " 'balak',\n",
       " 'balakayojan',\n",
       " 'balanc',\n",
       " 'balay',\n",
       " 'bale',\n",
       " 'bali',\n",
       " 'balik',\n",
       " 'balita',\n",
       " 'ballpen',\n",
       " 'bang',\n",
       " 'bangag',\n",
       " 'bank',\n",
       " 'bansa',\n",
       " 'bantay',\n",
       " 'baon',\n",
       " 'bar',\n",
       " 'barangay',\n",
       " 'bardagulan',\n",
       " 'barkada',\n",
       " 'barter',\n",
       " 'bartlebi',\n",
       " 'basa',\n",
       " 'basag',\n",
       " 'basahin',\n",
       " 'base',\n",
       " 'bash',\n",
       " 'basic',\n",
       " 'basketbal',\n",
       " 'basta',\n",
       " 'basto',\n",
       " 'basura',\n",
       " 'bat',\n",
       " 'bata',\n",
       " 'batang',\n",
       " 'batanga',\n",
       " 'batch',\n",
       " 'bath',\n",
       " 'batok',\n",
       " 'batteri',\n",
       " 'bawa',\n",
       " 'bawal',\n",
       " 'bawasan',\n",
       " 'bawi',\n",
       " 'bay',\n",
       " 'baya',\n",
       " 'bayad',\n",
       " 'bayan',\n",
       " 'bayaran',\n",
       " 'bayarin',\n",
       " 'bayut',\n",
       " 'bc',\n",
       " 'bcoz',\n",
       " 'bday',\n",
       " 'be',\n",
       " 'beauti',\n",
       " 'beb',\n",
       " 'bebe',\n",
       " 'bec',\n",
       " 'becom',\n",
       " 'bed',\n",
       " 'begin',\n",
       " 'beh',\n",
       " 'behalf',\n",
       " 'behav',\n",
       " 'behind',\n",
       " 'beke',\n",
       " 'believ',\n",
       " 'belong',\n",
       " 'benefit',\n",
       " 'benta',\n",
       " 'besid',\n",
       " 'best',\n",
       " 'besti',\n",
       " 'bet',\n",
       " 'beyond',\n",
       " 'bfast',\n",
       " 'bgo',\n",
       " 'bhe',\n",
       " 'bhi',\n",
       " 'bhie',\n",
       " 'bia',\n",
       " 'bibigyan',\n",
       " 'bibilhin',\n",
       " 'bibili',\n",
       " 'bibl',\n",
       " 'bicol',\n",
       " 'bida',\n",
       " 'bidang',\n",
       " 'big',\n",
       " 'bigat',\n",
       " 'bigay',\n",
       " 'bigla',\n",
       " 'biglang',\n",
       " 'bigyan',\n",
       " 'bike',\n",
       " 'bilhan',\n",
       " 'bilhin',\n",
       " 'bili',\n",
       " 'bilib',\n",
       " 'bill',\n",
       " 'billion',\n",
       " 'binaba',\n",
       " 'binabasa',\n",
       " 'binenta',\n",
       " 'binibigay',\n",
       " 'binigay',\n",
       " 'binigyan',\n",
       " 'binili',\n",
       " 'biochem',\n",
       " 'biro',\n",
       " 'birthday',\n",
       " 'biruin',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'biyah',\n",
       " 'biz',\n",
       " 'black',\n",
       " 'blackpenday',\n",
       " 'blackpink',\n",
       " 'blah',\n",
       " 'blame',\n",
       " 'blend',\n",
       " 'blendedlearn',\n",
       " 'bless',\n",
       " 'block',\n",
       " 'blog',\n",
       " 'blood',\n",
       " 'blotchi',\n",
       " 'blue',\n",
       " 'blur',\n",
       " 'bo',\n",
       " 'board',\n",
       " 'bobo',\n",
       " 'bobong',\n",
       " 'bodi',\n",
       " 'bogo',\n",
       " 'bohai',\n",
       " 'boi',\n",
       " 'boil',\n",
       " 'bond',\n",
       " 'bong',\n",
       " 'bongga',\n",
       " 'bongmadridoneb',\n",
       " 'book',\n",
       " 'bore',\n",
       " 'boredom',\n",
       " 'boset',\n",
       " 'boss',\n",
       " 'box',\n",
       " 'boxer',\n",
       " 'boy',\n",
       " 'boycott',\n",
       " 'boyfriend',\n",
       " 'brain',\n",
       " 'brand',\n",
       " 'brb',\n",
       " 'break',\n",
       " 'breakdown',\n",
       " 'breakfast',\n",
       " 'breakout',\n",
       " 'brell',\n",
       " 'brgi',\n",
       " 'brief',\n",
       " 'bright',\n",
       " 'bring',\n",
       " 'brion',\n",
       " 'bro',\n",
       " 'broadband',\n",
       " 'broken',\n",
       " 'brother',\n",
       " 'brownout',\n",
       " 'bruh',\n",
       " 'bsn',\n",
       " 'bt',\n",
       " 'btw',\n",
       " 'bubbl',\n",
       " 'bubungad',\n",
       " 'buburahin',\n",
       " 'buddi',\n",
       " 'budget',\n",
       " 'budhindi',\n",
       " 'budol',\n",
       " 'bugbog',\n",
       " 'buhay',\n",
       " 'buhok',\n",
       " 'build',\n",
       " 'builhind',\n",
       " 'buka',\n",
       " 'bukass',\n",
       " 'bukassss',\n",
       " 'buknoy',\n",
       " 'bukod',\n",
       " 'buksan',\n",
       " 'bulacan',\n",
       " 'bulag',\n",
       " 'bulli',\n",
       " 'bullshit',\n",
       " 'bulok',\n",
       " 'bulsa',\n",
       " 'bumaba',\n",
       " 'bumabag',\n",
       " 'bumabagyo',\n",
       " 'bumabangon',\n",
       " 'bumagsak',\n",
       " 'bumalik',\n",
       " 'bumangon',\n",
       " 'bumili',\n",
       " 'bundok',\n",
       " 'bungad',\n",
       " 'bungol',\n",
       " 'bunso',\n",
       " 'buong',\n",
       " 'burden',\n",
       " 'burn',\n",
       " 'burnout',\n",
       " 'buset',\n",
       " 'busi',\n",
       " 'buti',\n",
       " 'butter',\n",
       " 'button',\n",
       " 'buwan',\n",
       " 'buy',\n",
       " 'bwa',\n",
       " 'bwakanangshit',\n",
       " 'bwct',\n",
       " 'bwesit',\n",
       " 'bwiset',\n",
       " 'bwisit',\n",
       " 'byah',\n",
       " 'bye',\n",
       " 'cabl',\n",
       " 'cabuyao',\n",
       " 'cake',\n",
       " 'calculu',\n",
       " 'call',\n",
       " 'calm',\n",
       " 'cam',\n",
       " 'camera',\n",
       " 'campu',\n",
       " 'cancel',\n",
       " 'cant',\n",
       " 'canton',\n",
       " 'canva',\n",
       " 'cap',\n",
       " 'capabl',\n",
       " 'capac',\n",
       " 'card',\n",
       " 'care',\n",
       " 'career',\n",
       " 'carri',\n",
       " 'cart',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'cassi',\n",
       " 'cassylegaspi',\n",
       " 'casual',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'caus',\n",
       " 'cavit',\n",
       " 'celebr',\n",
       " 'cell',\n",
       " 'cellphon',\n",
       " 'center',\n",
       " 'cepat',\n",
       " 'ceremoni',\n",
       " 'certain',\n",
       " 'cha',\n",
       " 'chair',\n",
       " 'challeng',\n",
       " 'chanc',\n",
       " 'chang',\n",
       " 'chaotic',\n",
       " 'char',\n",
       " 'charg',\n",
       " 'charger',\n",
       " 'charm',\n",
       " 'charot',\n",
       " 'charrr',\n",
       " 'charrrr',\n",
       " 'chase',\n",
       " 'chat',\n",
       " 'cheap',\n",
       " 'cheat',\n",
       " 'checheckan',\n",
       " 'check',\n",
       " 'ched',\n",
       " 'cheer',\n",
       " 'chem',\n",
       " 'cher',\n",
       " 'cheret',\n",
       " 'chika',\n",
       " 'chikaaa',\n",
       " 'chikahan',\n",
       " 'child',\n",
       " 'chill',\n",
       " 'china',\n",
       " 'chismi',\n",
       " 'chismisan',\n",
       " 'chocol',\n",
       " 'choic',\n",
       " 'choos',\n",
       " 'choppi',\n",
       " 'chore',\n",
       " 'chour',\n",
       " 'choz',\n",
       " 'chriss',\n",
       " 'christma',\n",
       " 'chuchu',\n",
       " 'chz',\n",
       " 'circl',\n",
       " 'circuit',\n",
       " 'citi',\n",
       " 'claim',\n",
       " 'classic',\n",
       " 'classmat',\n",
       " 'classÃ°Ã¿',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'clearer',\n",
       " 'click',\n",
       " 'client',\n",
       " 'climb',\n",
       " 'clingi',\n",
       " 'clinic',\n",
       " 'clock',\n",
       " 'close',\n",
       " 'coconduct',\n",
       " 'cod',\n",
       " 'code',\n",
       " 'codm',\n",
       " 'coffe',\n",
       " 'collect',\n",
       " 'colleg',\n",
       " 'color',\n",
       " 'come',\n",
       " 'comeback',\n",
       " 'comfort',\n",
       " 'comm',\n",
       " 'comment',\n",
       " 'commiss',\n",
       " 'commission',\n",
       " 'commit',\n",
       " 'common',\n",
       " 'commun',\n",
       " 'compani',\n",
       " 'compar',\n",
       " 'compet',\n",
       " 'competit',\n",
       " 'complain',\n",
       " 'complaint',\n",
       " 'complet',\n",
       " 'compli',\n",
       " 'complianc',\n",
       " 'compr',\n",
       " 'comprehens',\n",
       " 'comput',\n",
       " 'con',\n",
       " 'concentr',\n",
       " 'concern',\n",
       " 'conclud',\n",
       " 'conclus',\n",
       " 'concret',\n",
       " 'condo',\n",
       " 'conduc',\n",
       " 'conduct',\n",
       " 'confer',\n",
       " 'confid',\n",
       " 'confirm',\n",
       " 'conflict',\n",
       " 'confus',\n",
       " 'congrat',\n",
       " 'congratul',\n",
       " 'conhindit',\n",
       " 'connect',\n",
       " 'consciou',\n",
       " 'consid',\n",
       " 'consider',\n",
       " 'consist',\n",
       " 'constant',\n",
       " 'consult',\n",
       " 'consum',\n",
       " 'contact',\n",
       " 'content',\n",
       " 'contest',\n",
       " 'continu',\n",
       " 'control',\n",
       " 'conveni',\n",
       " 'converg',\n",
       " 'convers',\n",
       " 'convert',\n",
       " 'cook',\n",
       " 'cool',\n",
       " 'cooper',\n",
       " 'cope',\n",
       " 'copi',\n",
       " 'corner',\n",
       " 'cost',\n",
       " 'cotabato',\n",
       " 'could',\n",
       " 'count',\n",
       " 'countri',\n",
       " 'coupl',\n",
       " 'courag',\n",
       " 'cours',\n",
       " 'court',\n",
       " 'cousin',\n",
       " 'cover',\n",
       " 'covid',\n",
       " 'coz',\n",
       " 'crap',\n",
       " 'crave',\n",
       " 'crazi',\n",
       " 'cream',\n",
       " 'creat',\n",
       " 'creativ',\n",
       " 'crehindit',\n",
       " 'cri',\n",
       " 'crisi',\n",
       " 'crucial',\n",
       " 'crush',\n",
       " 'ctrl',\n",
       " 'culinari',\n",
       " 'curiou',\n",
       " 'current',\n",
       " 'curriculum',\n",
       " 'curs',\n",
       " 'custom',\n",
       " 'cut',\n",
       " 'cute',\n",
       " 'cuti',\n",
       " 'cuz',\n",
       " 'cycl',\n",
       " 'cyst',\n",
       " 'dad',\n",
       " 'dadaan',\n",
       " 'dadagdag',\n",
       " 'dadat',\n",
       " 'daddi',\n",
       " 'dae',\n",
       " 'dagat',\n",
       " 'dagdag',\n",
       " 'daghan',\n",
       " 'dahan',\n",
       " 'dahilan',\n",
       " 'dai',\n",
       " 'daig',\n",
       " 'daili',\n",
       " 'dala',\n",
       " 'dalang',\n",
       " 'dalawang',\n",
       " 'daldal',\n",
       " 'daldalan',\n",
       " 'dale',\n",
       " 'dali',\n",
       " 'daloy',\n",
       " 'dam',\n",
       " 'dama',\n",
       " 'damag',\n",
       " 'damang',\n",
       " 'damay',\n",
       " 'dame',\n",
       " 'dami',\n",
       " 'damit',\n",
       " 'damn',\n",
       " 'danc',\n",
       " 'darat',\n",
       " 'darryl',\n",
       " 'daryl',\n",
       " 'dasal',\n",
       " 'dat',\n",
       " 'data',\n",
       " 'date',\n",
       " 'dati',\n",
       " 'datingan',\n",
       " 'daughter',\n",
       " 'davao',\n",
       " 'david',\n",
       " 'daw',\n",
       " 'day',\n",
       " 'dayon',\n",
       " 'dayun',\n",
       " 'dba',\n",
       " 'deac',\n",
       " 'deact',\n",
       " 'deactiv',\n",
       " 'dead',\n",
       " 'deadlin',\n",
       " 'deal',\n",
       " 'dean',\n",
       " 'dear',\n",
       " 'death',\n",
       " 'decemb',\n",
       " 'decid',\n",
       " 'decis',\n",
       " 'declar',\n",
       " 'dedma',\n",
       " 'deep',\n",
       " 'defendacademicfreedom',\n",
       " 'defendup',\n",
       " 'defin',\n",
       " 'definit',\n",
       " 'degre',\n",
       " 'dein',\n",
       " 'delay',\n",
       " 'delet',\n",
       " 'delikado',\n",
       " 'deliv',\n",
       " 'deliveri',\n",
       " 'demand',\n",
       " 'demanhind',\n",
       " 'demo',\n",
       " 'demonstr',\n",
       " 'demonyo',\n",
       " 'demotiv',\n",
       " 'den',\n",
       " 'dent',\n",
       " 'depart',\n",
       " 'depe',\n",
       " 'depend',\n",
       " 'depress',\n",
       " 'dept',\n",
       " 'deputa',\n",
       " 'deretso',\n",
       " 'deserv',\n",
       " 'design',\n",
       " 'desihindido',\n",
       " 'desisyon',\n",
       " 'despit',\n",
       " 'detail',\n",
       " 'detox',\n",
       " 'devic',\n",
       " 'dhenat',\n",
       " 'die',\n",
       " 'dko',\n",
       " 'do',\n",
       " 'dobl',\n",
       " 'doc',\n",
       " 'doctor',\n",
       " 'doesnt',\n",
       " 'dog',\n",
       " 'doh',\n",
       " 'doin',\n",
       " 'donat',\n",
       " 'donbosco',\n",
       " 'donee',\n",
       " 'dont',\n",
       " 'door',\n",
       " 'dorm',\n",
       " 'dose',\n",
       " 'dota',\n",
       " 'doubl',\n",
       " 'doubt',\n",
       " 'download',\n",
       " 'downsid',\n",
       " 'draft',\n",
       " 'drain',\n",
       " 'drama',\n",
       " 'drastic',\n",
       " 'draw',\n",
       " 'dream',\n",
       " 'dri',\n",
       " 'drink',\n",
       " 'drive',\n",
       " 'driver',\n",
       " 'drop',\n",
       " 'drug',\n",
       " 'dto',\n",
       " 'duda',\n",
       " 'dude',\n",
       " 'due',\n",
       " 'dugo',\n",
       " 'duha',\n",
       " 'dulot',\n",
       " 'dumaan',\n",
       " 'dumagdag',\n",
       " 'dumami',\n",
       " 'dumat',\n",
       " 'dumb',\n",
       " 'dun',\n",
       " 'dutert',\n",
       " 'duti',\n",
       " 'dvd',\n",
       " 'dyan',\n",
       " 'dylan',\n",
       " 'dynamit',\n",
       " 'dzae',\n",
       " 'dzai',\n",
       " 'dzaii',\n",
       " 'ean',\n",
       " 'earli',\n",
       " 'earlier',\n",
       " 'earn',\n",
       " 'earphon',\n",
       " 'earth',\n",
       " 'eas',\n",
       " 'easi',\n",
       " 'easili',\n",
       " 'eat',\n",
       " 'echo',\n",
       " 'ecq',\n",
       " 'educ',\n",
       " 'edukasyon',\n",
       " 'eemail',\n",
       " 'eenjoy',\n",
       " 'eenrol',\n",
       " 'eexcit',\n",
       " 'effect',\n",
       " 'effici',\n",
       " 'effin',\n",
       " 'effort',\n",
       " 'ego',\n",
       " 'egul',\n",
       " 'ehe',\n",
       " 'ehh',\n",
       " 'ehhh',\n",
       " 'ehindi',\n",
       " 'ehindit',\n",
       " 'either',\n",
       " 'eki',\n",
       " 'eksena',\n",
       " 'elem',\n",
       " 'elementari',\n",
       " 'els',\n",
       " 'embarrass',\n",
       " 'eme',\n",
       " 'emerg',\n",
       " 'emot',\n",
       " 'empleyado',\n",
       " 'empti',\n",
       " 'encourag',\n",
       " 'end',\n",
       " 'endur',\n",
       " 'energi',\n",
       " 'engag',\n",
       " 'engin',\n",
       " 'english',\n",
       " 'enhind',\n",
       " 'enhypen',\n",
       " 'enjoy',\n",
       " 'enough',\n",
       " 'enrol',\n",
       " 'enter',\n",
       " 'entir',\n",
       " 'environ',\n",
       " 'eon',\n",
       " 'epal',\n",
       " 'epekto',\n",
       " 'epic',\n",
       " 'episod',\n",
       " 'equal',\n",
       " 'equat',\n",
       " 'equip',\n",
       " 'era',\n",
       " 'error',\n",
       " 'escap',\n",
       " 'eskwela',\n",
       " 'esp',\n",
       " 'especi',\n",
       " 'essenti',\n",
       " 'est',\n",
       " 'estudyant',\n",
       " 'estudyanteng',\n",
       " 'etc',\n",
       " 'eto',\n",
       " 'etong',\n",
       " 'even',\n",
       " 'event',\n",
       " ...]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Accuracy rate before Using Imbalanced learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Multinomial Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Complement Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Bernoulli Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resample, y_resample = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_resample.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MNB for this dataset: 61.17\n"
     ]
    }
   ],
   "source": [
    "#1 Multinomial Naive Bayes\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "#train our algorithm\n",
    "mnb.fit(X_resample, y_resample)\n",
    "\n",
    "#Test the trained classifier\n",
    "predicted_class = mnb.predict(X_test)\n",
    "print('Accuracy of MNB for this dataset: %3.2f' %  (accuracy_score(y_test, predicted_class)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MNB for this dataset: 58.67\n"
     ]
    }
   ],
   "source": [
    "cnb = ComplementNB()\n",
    "\n",
    "cnb.fit(X_resample, y_resample)\n",
    "predicted_class = cnb.predict(X_test)\n",
    "print('Accuracy of MNB for this dataset: %3.2f' %  (accuracy_score(y_test, predicted_class)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Gaussian Naive Bayes for this dataset: 63.92\n"
     ]
    }
   ],
   "source": [
    "#3 Bernoulli Naive Bayes classifier\n",
    "nb = BernoulliNB()\n",
    "\n",
    "# Fit the model\n",
    "nb.fit(X_resample, y_resample)\n",
    "\n",
    "predicted_class = nb.predict(X_test)\n",
    "print('Accuracy of Gaussian Naive Bayes for this dataset: %3.2f' %  (accuracy_score(y_test, predicted_class)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = \"ang saya ng online class\"\n",
    "clean = process_tweets(str.lower(words))\n",
    "clean = NormalizeWithPOS(clean)\n",
    "words = vectorizer.transform([clean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive'], dtype='<U8')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive'], dtype='<U8')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnb.predict(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive'], dtype='<U8')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[671 161  93]\n",
      " [250 467 191]\n",
      " [ 38  44  86]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.70      0.73      0.71       925\n",
      "     Neutral       0.69      0.51      0.59       908\n",
      "    Positive       0.23      0.51      0.32       168\n",
      "\n",
      "    accuracy                           0.61      2001\n",
      "   macro avg       0.54      0.58      0.54      2001\n",
      "weighted avg       0.66      0.61      0.62      2001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Naive Bayes \n",
    "confussionMatrix(mnb,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[668 154 103]\n",
      " [280 412 216]\n",
      " [ 36  38  94]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.68      0.72      0.70       925\n",
      "     Neutral       0.68      0.45      0.54       908\n",
      "    Positive       0.23      0.56      0.32       168\n",
      "\n",
      "    accuracy                           0.59      2001\n",
      "   macro avg       0.53      0.58      0.52      2001\n",
      "weighted avg       0.64      0.59      0.60      2001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Complement Naive Bayes \n",
    "confussionMatrix(cnb,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[633 223  69]\n",
      " [193 586 129]\n",
      " [ 37  71  60]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.73      0.68      0.71       925\n",
      "     Neutral       0.67      0.65      0.66       908\n",
      "    Positive       0.23      0.36      0.28       168\n",
      "\n",
      "    accuracy                           0.64      2001\n",
      "   macro avg       0.54      0.56      0.55      2001\n",
      "weighted avg       0.66      0.64      0.65      2001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Bernoulli Naive Bayes\n",
    "confussionMatrix(nb,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionmt(cl, X_test, y_test):\n",
    "    # Predict the labels\n",
    "    y_pred = cl.predict(X_test)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    total = cm.sum().sum()\n",
    "    accuracy = np.diag(cm).sum() / total\n",
    "    accuracy = accuracy * 100\n",
    "    accuracy = round(accuracy, 2)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnbacc = confusionmt(mnb, X_test, y_test)\n",
    "cnbacc = confusionmt(cnb, X_test, y_test)\n",
    "bnbacc = confusionmt(nb, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61.17, 58.67, 63.92]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "accuracy = [mnbacc, cnbacc, bnbacc]\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(accuracy, open(\"acc.pkl\", 'wb'))\n",
    "pickle.dump(mnb, open(\"MNB_model.pkl\", 'wb'))\n",
    "pickle.dump(cnb, open(\"CNB_model.pkl\", 'wb'))\n",
    "pickle.dump(nb, open(\"BNB_model.pkl\", 'wb'))\n",
    "pickle.dump(vectorizer, open(\"vectorizer.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
